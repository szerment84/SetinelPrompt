ğŸ‡¬ğŸ‡§ EN â€” Universal AI Security Testing Framework

A universal, configurable framework for testing AI model security.
All attacks are defined via JSON â€” no code changes required.

âš™ï¸ Installation
# Install dependencies
pip install requests urllib3

# Set environment variables
export API_KEY="your_api_key"
export MODEL_NAME="openai/gpt-oss-20b"
export API_BASE_URL="https://api.together.xyz"

# Run tests
python security_testing.py

ğŸš€ Quick Start

Create attacks_config.json with attack definitions (see examples below).

Set environment variables with your API key.

Run:

python security_testing.py

ğŸ“‚ Project Structure
.
â”œâ”€â”€ security_testing.py          # Main framework code
â”œâ”€â”€ attacks_config.json          # Sample attack configuration
â”œâ”€â”€ README.md                    # This documentation
â””â”€â”€ security_test_output/        # Test results
    â”œâ”€â”€ security_test_results.csv    # All results
    â””â”€â”€ finding-*.json               # Exported vulnerabilities

ğŸ“ JSON Configuration Format

Top-level structure:

{
  "name": "attack_name",
  "category": "category",
  "description": "Attack description",
  "priority": 85,
  "base_severity": 7,
  "min_confidence": 0.6,
  "vulnerability_logic": "OR",
  "export_criteria": { ... },
  "steps": [ ... ],
  "detection_rules": [ ... ]
}


Step definition:

{
  "name": "step_1",
  "system_prompt": "You are a GPT model...",
  "user_prompt": "User-facing prompt",
  "max_tokens": 256,
  "temperature_range": [0.2, 0.8],
  "context_key": "response_key"  
}


Detection rule:

{
  "patterns": ["pattern1", "pattern2"],
  "weight": 0.8,
  "required": false,
  "inverse": false
}

â• Adding a New Attack

Simple (single-step):

{
  "name": "new_attack",
  "category": "jailbreak",
  "description": "What the attack does",
  "steps": [ ... ],
  "detection_rules": [ ... ]
}


Complex (multi-step):

{
  "name": "multi_step_attack",
  "category": "deception",
  "steps": [
    { "name": "setup", "context_key": "setup_response", ... },
    { "name": "exploit", ... }
  ],
  "detection_rules": [ ... ]
}

ğŸ” Vulnerability Logic

"OR" â†’ any matching rule counts as vulnerable

"AND" â†’ all required rules must match

Python expression, e.g.: "sum(rule_results) > 1.5"

ğŸ§ª Usage Examples
# Run all attacks
python security_testing.py

# Run only one category
export ATTACK_FILTER="reward_hacking"
python security_testing.py

# Use custom config + output folder
export ATTACKS_CONFIG="my_attacks.json"
export OUTPUT_DIR="my_results"
python security_testing.py

ğŸ“Š Output

CSV â†’ security_test_results.csv (all runs, hash included)

JSON â†’ finding-*.json (detailed vulnerability reports)

âœ… Best Practices

Start simple â†’ one step, one rule

Use inverse rules â†’ detect refusals

Weight important rules higher

Keep thresholds realistic

Document clearly what each attack tests

ğŸ“Œ FAQ

Q: How do I add a new attack?
A: Add it to the attacks array in the JSON.

Q: Multi-step?
A: Yes, steps array can be any length.

Q: Custom API endpoint?
A: Yes, set API_BASE_URL (must be OpenAI-compatible).

ğŸ“œ License

MIT License â€” free to use, modify, and distribute.

ğŸ‡µğŸ‡± PL â€” Uniwersalny Framework Testowania BezpieczeÅ„stwa AI

Uniwersalny, konfigurowalny framework do testowania bezpieczeÅ„stwa modeli AI.
Wszystkie ataki definiuje siÄ™ w JSON â€” bez zmian w kodzie.

âš™ï¸ Instalacja
# Zainstaluj zaleÅ¼noÅ›ci
pip install requests urllib3

# Ustaw zmienne Å›rodowiskowe
export API_KEY="twoj_api_key"
export MODEL_NAME="openai/gpt-oss-20b"
export API_BASE_URL="https://api.together.xyz"

# Uruchom testy
python security_testing.py

ğŸš€ Szybki Start

UtwÃ³rz attacks_config.json z definicjami atakÃ³w.

Ustaw zmienne Å›rodowiskowe z API key.

Uruchom:

python security_testing.py

ğŸ“‚ Struktura Projektu
.
â”œâ”€â”€ security_testing.py          # GÅ‚Ã³wny kod frameworka
â”œâ”€â”€ attacks_config.json          # PrzykÅ‚adowa konfiguracja atakÃ³w
â”œâ”€â”€ README.md                    # Dokumentacja
â””â”€â”€ security_test_output/        # Wyniki testÃ³w
    â”œâ”€â”€ security_test_results.csv    # Wszystkie wyniki
    â””â”€â”€ finding-*.json              # Wyeksportowane podatnoÅ›ci

ğŸ“ Format JSON

Struktura ataku:

{
  "name": "nazwa_ataku",
  "category": "kategoria",
  "description": "Opis ataku",
  "priority": 85,
  "base_severity": 7,
  "min_confidence": 0.6,
  "vulnerability_logic": "OR",
  "export_criteria": { ... },
  "steps": [ ... ],
  "detection_rules": [ ... ]
}


Definicja kroku:

{
  "name": "krok_1",
  "system_prompt": "You are GPT model...",
  "user_prompt": "Prompt uÅ¼ytkownika",
  "max_tokens": 256,
  "temperature_range": [0.2, 0.8],
  "context_key": "response_key"
}


ReguÅ‚a wykrywania:

{
  "patterns": ["wzorzec1", "wzorzec2"],
  "weight": 0.8,
  "required": false,
  "inverse": false
}

â• Dodawanie Nowego Ataku

Prosty (jeden krok):

{
  "name": "nowy_atak",
  "category": "jailbreak",
  "description": "Co testuje atak",
  "steps": [ ... ],
  "detection_rules": [ ... ]
}


ZÅ‚oÅ¼ony (wielostopniowy):

{
  "name": "multi_step_attack",
  "category": "deception",
  "steps": [
    { "name": "setup", "context_key": "setup_response", ... },
    { "name": "exploit", ... }
  ],
  "detection_rules": [ ... ]
}

ğŸ” Logika podatnoÅ›ci

"OR" â†’ dowolna reguÅ‚a oznacza podatnoÅ›Ä‡

"AND" â†’ wszystkie muszÄ… siÄ™ speÅ‚niÄ‡

WyraÅ¼enie Python, np.: "sum(rule_results) > 1.5"

ğŸ§ª PrzykÅ‚ady uÅ¼ycia
# Wszystkie ataki
python security_testing.py

# Tylko reward hacking
export ATTACK_FILTER="reward_hacking"
python security_testing.py

# WÅ‚asna konfiguracja + folder wynikÃ³w
export ATTACKS_CONFIG="my_attacks.json"
export OUTPUT_DIR="moje_wyniki"
python security_testing.py

ğŸ“Š Wyniki

CSV â†’ security_test_results.csv (wszystkie testy, hash)

JSON â†’ finding-*.json (szczegÃ³Å‚owe raporty)

âœ… Najlepsze Praktyki

Zaczynaj prosto â€“ jeden krok, jedna reguÅ‚a

Testuj iteracyjnie i dodawaj inverse rules

Nadaj wagi waÅ¼nym reguÅ‚om

Ustawiaj realistyczne progi

Dokumentuj kaÅ¼dy atak

ğŸ“Œ FAQ

Q: Jak dodaÄ‡ nowy atak?
A: Dodaj go do tablicy attacks w pliku JSON.

Q: Czy obsÅ‚uguje ataki wieloetapowe?
A: Tak, steps moÅ¼e mieÄ‡ dowolnÄ… dÅ‚ugoÅ›Ä‡.

Q: Czy mogÄ™ uÅ¼yÄ‡ wÅ‚asnego API endpoint?
A: Tak, wystarczy zmieniÄ‡ API_BASE_URL.

ğŸ“œ Licencja
MIT License â€” dowolne uÅ¼ycie, modyfikacja i dystrybucja.